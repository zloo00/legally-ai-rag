#!/usr/bin/env python3
"""
Benchmark –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ RAG —Å–∏—Å—Ç–µ–º—ã
–í–∫–ª—é—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏, —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –ø–æ–ª–Ω–æ—Ç—ã
"""

import os
import time
import json
import statistics
from datetime import datetime
from typing import List, Dict, Any, Tuple
import pandas as pd
from dotenv import load_dotenv
import re

from rag_system import EnhancedRAGSystem
from rag_factory import EnhancedRAGSystem

rag = EnhancedRAGSystem()

load_dotenv()

class QualityBenchmark:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, output_dir: str = "benchmark_results"):
        self.output_dir = output_dir
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        os.makedirs(output_dir, exist_ok=True)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏
        self.quality_questions = [
            {
                "question": "–ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç —Å—Ç–∞—Ç—å—è 1 –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–ö?",
                "expected_keywords": ["–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–µ –ø—Ä–∞–≤–æ", "–æ—Ç–Ω–æ—à–µ–Ω–∏—è", "–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ", "–ª–∏—á–Ω—ã–µ", "–Ω–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ"],
                "expected_sources": ["–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å", "—Å—Ç–∞—Ç—å—è 1"],
                "expected_article_number": "1",
                "expected_code": "–ì–ö"
            },
            {
                "question": "–ö–∞–∫–∏–µ –ø—Ä–∞–≤–∞ –∏–º–µ–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫ –∏–º—É—â–µ—Å—Ç–≤–∞?",
                "expected_keywords": ["–≤–ª–∞–¥–µ–Ω–∏–µ", "–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ", "—Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–µ", "—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–ø—Ä–∞–≤–∞"],
                "expected_sources": ["–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å", "–ø—Ä–∞–≤–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏"],
                "expected_article_number": None,
                "expected_code": "–ì–ö"
            },
            {
                "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä?",
                "expected_keywords": ["—Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä", "—Ä–∞–±–æ—Ç–Ω–∏–∫", "—Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å", "—Ç—Ä—É–¥–æ–≤—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è", "—Å–æ–≥–ª–∞—à–µ–Ω–∏–µ"],
                "expected_sources": ["–¢—Ä—É–¥–æ–≤–æ–π –∫–æ–¥–µ–∫—Å", "—Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä"],
                "expected_article_number": None,
                "expected_code": "–¢–ö"
            },
            {
                "question": "–ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–∏—è –¥–ª—è —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏—è –±—Ä–∞–∫–∞?",
                "expected_keywords": ["—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ", "–±—Ä–∞–∫", "–æ—Å–Ω–æ–≤–∞–Ω–∏—è", "—Ä–∞–∑–≤–æ–¥", "—Å—É–¥"],
                "expected_sources": ["–°–µ–º–µ–π–Ω—ã–π –∫–æ–¥–µ–∫—Å", "–±—Ä–∞–∫"],
                "expected_article_number": None,
                "expected_code": "–°–ö"
            },
            {
                "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ –∑–∞–∫–æ–Ω—É?",
                "expected_keywords": ["–Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "–∑–∞–∫–æ–Ω", "–Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∏", "–æ—á–µ—Ä–µ–¥—å", "–∏–º—É—â–µ—Å—Ç–≤–æ"],
                "expected_sources": ["–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å", "–Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"],
                "expected_article_number": None,
                "expected_code": "–ì–ö"
            },
            {
                "question": "–ö–∞–∫–∏–µ –≤–∏–¥—ã –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω—ã –≤ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –ø—Ä–∞–≤–µ?",
                "expected_keywords": ["–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–µ –ø—Ä–∞–≤–æ", "–≤–∏–¥—ã", "—É—â–µ—Ä–±", "–≤–æ–∑–º–µ—â–µ–Ω–∏–µ"],
                "expected_sources": ["–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å", "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å"],
                "expected_article_number": None,
                "expected_code": "–ì–ö"
            },
            {
                "question": "–ö–∞–∫ –∑–∞—â–∏—â–∞—é—Ç—Å—è –ø—Ä–∞–≤–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π?",
                "expected_keywords": ["–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏", "–ø—Ä–∞–≤–∞", "–∑–∞—â–∏—Ç–∞", "—Ç–æ–≤–∞—Ä—ã", "—É—Å–ª—É–≥–∏"],
                "expected_sources": ["–ó–∞–∫–æ–Ω –æ –∑–∞—â–∏—Ç–µ –ø—Ä–∞–≤ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π", "–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏"],
                "expected_article_number": None,
                "expected_code": "–ó–ó–ü–ü"
            },
            {
                "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å?",
                "expected_keywords": ["–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è", "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏–µ", "—à—Ç—Ä–∞—Ñ", "–Ω–∞–∫–∞–∑–∞–Ω–∏–µ"],
                "expected_sources": ["–ö–æ–¥–µ–∫—Å –æ–± –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏—è—Ö", "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å"],
                "expected_article_number": None,
                "expected_code": "–ö–æ–ê–ü"
            },
            {
                "question": "–ö–∞–∫–∏–µ –ø—Ä–∞–≤–∞ –∏–º–µ–µ—Ç —Ä–∞–±–æ—Ç–Ω–∏–∫ –ø—Ä–∏ —É–≤–æ–ª—å–Ω–µ–Ω–∏–∏?",
                "expected_keywords": ["—Ä–∞–±–æ—Ç–Ω–∏–∫", "—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ", "–ø—Ä–∞–≤–∞", "–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è", "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ"],
                "expected_sources": ["–¢—Ä—É–¥–æ–≤–æ–π –∫–æ–¥–µ–∫—Å", "—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ"],
                "expected_article_number": None,
                "expected_code": "–¢–ö"
            },
            {
                "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ –ø—Ä–µ–∑—É–º–ø—Ü–∏—è –Ω–µ–≤–∏–Ω–æ–≤–Ω–æ—Å—Ç–∏?",
                "expected_keywords": ["–ø—Ä–µ–∑—É–º–ø—Ü–∏—è", "–Ω–µ–≤–∏–Ω–æ–≤–Ω–æ—Å—Ç—å", "—É–≥–æ–ª–æ–≤–Ω–æ–µ –ø—Ä–∞–≤–æ", "–æ–±–≤–∏–Ω–µ–Ω–∏–µ", "–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞"],
                "expected_sources": ["–£–≥–æ–ª–æ–≤–Ω—ã–π –∫–æ–¥–µ–∫—Å", "–ø—Ä–µ–∑—É–º–ø—Ü–∏—è –Ω–µ–≤–∏–Ω–æ–≤–Ω–æ—Å—Ç–∏"],
                "expected_article_number": None,
                "expected_code": "–£–ö"
            }
        ]

    def calculate_keyword_score(self, answer: str, expected_keywords: List[str]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        if not expected_keywords:
            return 0.0
        
        answer_lower = answer.lower()
        matches = sum(1 for keyword in expected_keywords if keyword.lower() in answer_lower)
        return matches / len(expected_keywords)

    def calculate_source_score(self, sources: List[str], expected_sources: List[str]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º"""
        if not expected_sources:
            return 0.0
        
        source_matches = 0
        for expected_source in expected_sources:
            for source in sources:
                if expected_source.lower() in source.lower():
                    source_matches += 1
                    break
        
        return source_matches / len(expected_sources)

    def calculate_article_number_score(self, answer: str, sources: List[str], expected_article_number: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç–∞—Ç—å–∏"""
        if not expected_article_number:
            return 0.0
        
        # –ò—â–µ–º –Ω–æ–º–µ—Ä —Å—Ç–∞—Ç—å–∏ –≤ –æ—Ç–≤–µ—Ç–µ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
        article_pattern = r'—Å—Ç–∞—Ç—å—è\s*' + re.escape(expected_article_number) + r'\b'
        
        answer_match = bool(re.search(article_pattern, answer, re.IGNORECASE))
        source_match = any(re.search(article_pattern, source, re.IGNORECASE) for source in sources)
        
        return 1.0 if (answer_match or source_match) else 0.0

    def calculate_code_score(self, sources: List[str], expected_code: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É –ø–æ –∫–æ–¥—É –∑–∞–∫–æ–Ω–∞"""
        if not expected_code:
            return 0.0
        
        code_patterns = [
            expected_code,
            expected_code + " –†–ö",
            expected_code + " –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω"
        ]
        
        for source in sources:
            for pattern in code_patterns:
                if pattern.lower() in source.lower():
                    return 1.0
        
        return 0.0

    def calculate_answer_length_score(self, answer: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É –ø–æ –¥–ª–∏–Ω–µ –æ—Ç–≤–µ—Ç–∞ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é)"""
        # –ò–¥–µ–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ - 200-500 —Å–∏–º–≤–æ–ª–æ–≤
        ideal_min = 200
        ideal_max = 500
        
        if len(answer) < ideal_min:
            return len(answer) / ideal_min
        elif len(answer) > ideal_max:
            return ideal_max / len(answer)
        else:
            return 1.0

    def calculate_sources_count_score(self, sources_count: int) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        # –ò–¥–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ - 2-5
        ideal_min = 2
        ideal_max = 5
        
        if sources_count < ideal_min:
            return sources_count / ideal_min
        elif sources_count > ideal_max:
            return ideal_max / sources_count
        else:
            return 1.0

    def calculate_relevance_score(self, answer: str, question: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å—É"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –≤ –æ—Ç–≤–µ—Ç–µ
        question_words = set(re.findall(r'\b\w+\b', question.lower()))
        answer_words = set(re.findall(r'\b\w+\b', answer.lower()))
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {'—á—Ç–æ', '–∫–∞–∫–∏–µ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–¥–ª—è', '—á–µ–≥–æ', '—ç—Ç–æ', '—Ç–∞–∫–æ–µ', '–∏–º–µ–µ—Ç', '–∏–º–µ–µ—Ç', '–∏–º–µ–µ—Ç'}
        question_words = question_words - stop_words
        answer_words = answer_words - stop_words
        
        if not question_words:
            return 0.0
        
        common_words = question_words.intersection(answer_words)
        return len(common_words) / len(question_words)

    def measure_quality_metrics(self, rag_system, question_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ò–∑–º–µ—Ä—è–µ—Ç –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞"""
        question = question_data["question"]
        expected_keywords = question_data.get("expected_keywords", [])
        expected_sources = question_data.get("expected_sources", [])
        expected_article_number = question_data.get("expected_article_number")
        expected_code = question_data.get("expected_code")
        
        try:
            result = rag_system.query(question)
            answer = result.get("answer", "")
            sources = result.get("sources", [])
            
            # –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
            keyword_score = self.calculate_keyword_score(answer, expected_keywords)
            source_score = self.calculate_source_score(sources, expected_sources)
            article_number_score = self.calculate_article_number_score(answer, sources, expected_article_number)
            code_score = self.calculate_code_score(sources, expected_code)
            answer_length_score = self.calculate_answer_length_score(answer)
            sources_count_score = self.calculate_sources_count_score(len(sources))
            relevance_score = self.calculate_relevance_score(answer, question)
            
            # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (–≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞)
            overall_score = (
                keyword_score * 0.25 +
                source_score * 0.20 +
                article_number_score * 0.15 +
                code_score * 0.15 +
                answer_length_score * 0.10 +
                sources_count_score * 0.10 +
                relevance_score * 0.05
            )
            
            return {
                "question": question,
                "answer": answer,
                "sources": sources,
                "keyword_score": keyword_score,
                "source_score": source_score,
                "article_number_score": article_number_score,
                "code_score": code_score,
                "answer_length_score": answer_length_score,
                "sources_count_score": sources_count_score,
                "relevance_score": relevance_score,
                "overall_score": overall_score,
                "answer_length": len(answer),
                "sources_count": len(sources)
            }
            
        except Exception as e:
            return {
                "question": question,
                "error": str(e),
                "keyword_score": 0,
                "source_score": 0,
                "article_number_score": 0,
                "code_score": 0,
                "answer_length_score": 0,
                "sources_count_score": 0,
                "relevance_score": 0,
                "overall_score": 0,
                "answer_length": 0,
                "sources_count": 0
            }

    def run_quality_benchmark(self, rag_system, engine_name: str = "baseline") -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç benchmark –∫–∞—á–µ—Å—Ç–≤–∞"""
        print(f"üéØ –ó–∞–ø—É—Å–∫ benchmark –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è {engine_name}")
        print("=" * 60)
        
        quality_results = []
        for i, question_data in enumerate(self.quality_questions, 1):
            print(f"[{i}/{len(self.quality_questions)}] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {question_data['question'][:50]}...")
            result = self.measure_quality_metrics(rag_system, question_data)
            quality_results.append(result)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        keyword_scores = [r["keyword_score"] for r in quality_results if "keyword_score" in r]
        source_scores = [r["source_score"] for r in quality_results if "source_score" in r]
        article_number_scores = [r["article_number_score"] for r in quality_results if "article_number_score" in r]
        code_scores = [r["code_score"] for r in quality_results if "code_score" in r]
        answer_length_scores = [r["answer_length_score"] for r in quality_results if "answer_length_score" in r]
        sources_count_scores = [r["sources_count_score"] for r in quality_results if "sources_count_score" in r]
        relevance_scores = [r["relevance_score"] for r in quality_results if "relevance_score" in r]
        overall_scores = [r["overall_score"] for r in quality_results if "overall_score" in r]
        
        quality_benchmark = {
            "engine": engine_name,
            "timestamp": datetime.now().isoformat(),
            "total_questions": len(self.quality_questions),
            "avg_keyword_score": statistics.mean(keyword_scores) if keyword_scores else 0,
            "avg_source_score": statistics.mean(source_scores) if source_scores else 0,
            "avg_article_number_score": statistics.mean(article_number_scores) if article_number_scores else 0,
            "avg_code_score": statistics.mean(code_scores) if code_scores else 0,
            "avg_answer_length_score": statistics.mean(answer_length_scores) if answer_length_scores else 0,
            "avg_sources_count_score": statistics.mean(sources_count_scores) if sources_count_scores else 0,
            "avg_relevance_score": statistics.mean(relevance_scores) if relevance_scores else 0,
            "avg_overall_score": statistics.mean(overall_scores) if overall_scores else 0,
            "quality_results": quality_results
        }
        
        return quality_benchmark

    def save_quality_results(self, results: Dict[str, Any], engine_name: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ –≤ —Ñ–∞–π–ª—ã"""
        # JSON —Ñ–∞–π–ª
        json_file = f"{self.output_dir}/quality_{engine_name}_{self.timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # CSV —Ñ–∞–π–ª —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        if "quality_results" in results:
            qual_df = pd.DataFrame(results["quality_results"])
            csv_file = f"{self.output_dir}/quality_details_{engine_name}_{self.timestamp}.csv"
            qual_df.to_csv(csv_file, index=False, encoding='utf-8')
        
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.output_dir}/")

    def run_full_quality_benchmark(self, engine_name: str = "baseline") -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π benchmark –∫–∞—á–µ—Å—Ç–≤–∞"""
        print(f"üéØ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ benchmark –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è {engine_name}")
        print("=" * 80)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG —Å–∏—Å—Ç–µ–º—É
        try:
            if engine_name == "baseline":
                rag_system = EnhancedRAGSystem()
            else:
                rag_system = RAGFactory.create_rag_system(engine_name)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ {engine_name}: {e}")
            return {"error": str(e)}
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º benchmark –∫–∞—á–µ—Å—Ç–≤–∞
        quality_result = self.run_quality_benchmark(rag_system, engine_name)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.save_quality_results(quality_result, engine_name)
        
        return quality_result

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ benchmark –∫–∞—á–µ—Å—Ç–≤–∞"""
    print("üéØ RAG Quality Benchmark")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    required_vars = ['OPENAI_API_KEY', 'PINECONE_API_KEY', 'PINECONE_INDEX_NAME']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {', '.join(missing_vars)}")
        return
    
    # –°–æ–∑–¥–∞–µ–º benchmark –∫–∞—á–µ—Å—Ç–≤–∞
    quality_benchmark = QualityBenchmark()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º benchmark –¥–ª—è baseline
    print("üöÄ –ó–∞–ø—É—Å–∫ benchmark –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è baseline –¥–≤–∏–∂–∫–∞...")
    quality_result = quality_benchmark.run_full_quality_benchmark("baseline")
    
    if "error" not in quality_result:
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞:")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {quality_result['avg_keyword_score']:.3f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º: {quality_result['avg_source_score']:.3f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –Ω–æ–º–µ—Ä–∞–º —Å—Ç–∞—Ç–µ–π: {quality_result['avg_article_number_score']:.3f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –∫–æ–¥–∞–º –∑–∞–∫–æ–Ω–æ–≤: {quality_result['avg_code_score']:.3f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –¥–ª–∏–Ω–µ –æ—Ç–≤–µ—Ç–æ–≤: {quality_result['avg_answer_length_score']:.3f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {quality_result['avg_sources_count_score']:.3f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {quality_result['avg_relevance_score']:.3f}")
        print(f"   –û–±—â–∞—è —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {quality_result['avg_overall_score']:.3f}")
    
    print("\nüéâ Benchmark –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {quality_benchmark.output_dir}/")

if __name__ == "__main__":
    main()

