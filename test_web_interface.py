#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ —á–∞—Ç–∞
"""

import requests
import json
import time
from bs4 import BeautifulSoup
import pandas as pd

def test_web_chat():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    base_url = "http://localhost:5001"
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∞—è –¥–µ–µ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å?",
        "–ö–∞–∫–∏–µ –ø—Ä–∞–≤–∞ –∏–º–µ–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫ –∏–º—É—â–µ—Å—Ç–≤–∞?",
        "–ö–∞–∫ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è —Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å?"
    ]
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ —á–∞—Ç–∞")
    print("=" * 60)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\nüìù –¢–µ—Å—Ç {i}: {question}")
        print("-" * 40)
        
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = requests.post(
                f"{base_url}/chat",
                json={"message": question},
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω")
                print(f"ü§ñ –†–µ–∂–∏–º: {data.get('mode', 'N/A')}")
                print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {data.get('results_count', 0)}")
                print(f"üìù –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {data.get('context_length', 0)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
                answer = data.get('answer', '')
                print(f"\nüí¨ –û—Ç–≤–µ—Ç:\n{answer[:300]}{'...' if len(answer) > 300 else ''}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
                search_results = data.get('search_results', [])
                if search_results:
                    print(f"\nüìö –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ ({len(search_results)}):")
                    for j, result in enumerate(search_results[:3], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                        print(f"  {j}. {result.get('source', 'N/A')} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {(result.get('score', 0) * 100):.1f}%)")
                        content = result.get('text', '')
                        print(f"     {content[:100]}{'...' if len(content) > 100 else ''}")
                
                print(f"\nüîó –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(data.get('sources', []))}")
                
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
                print(f"üìÑ –û—Ç–≤–µ—Ç: {response.text}")
                
        except requests.exceptions.ConnectionError:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:5001")
            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        
        time.sleep(1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    print("\n" + "=" * 60)
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üåê –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: {base_url}")

def get_page(url):
    resp = requests.get(url, headers=HEADERS)
    resp.raise_for_status()
    return resp.text

def parse_question_block(block):
    # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–∏—Ç—å –ø–æ —Ä–µ–∞–ª—å–Ω–æ–º—É HTML
    question = block.find("div", class_="question-text").get_text(strip=True)
    answer = block.find("div", class_="answer-text").get_text(strip=True)
    # –ï—Å–ª–∏ –µ—Å—Ç—å "–ß–∏—Ç–∞—Ç—å –¥–∞–ª—å—à–µ" ‚Äî –ø–∞—Ä—Å–∏–º —Å—Å—ã–ª–∫—É
    more_link = block.find("a", string="–ß–∏—Ç–∞—Ç—å –¥–∞–ª—å—à–µ")
    if more_link:
        answer = get_full_answer(BASE_URL + more_link["href"])
    return question, answer

def get_full_answer(url):
    html = get_page(url)
    soup = BeautifulSoup(html, "html.parser")
    answer = soup.find("div", class_="full-answer").get_text(strip=True)
    return answer

def parse_page(page_num):
    url = f"{BASE_URL}?page={page_num}"
    html = get_page(url)
    soup = BeautifulSoup(html, "html.parser")
    blocks = soup.find_all("div", class_="question-block")  # —É—Ç–æ—á–Ω–∏—Ç—å –∫–ª–∞—Å—Å
    data = []
    for block in blocks:
        question, answer = parse_question_block(block)
        data.append({"question": question, "answer": answer})
    return data

# –ü—Ä–∏–º–µ—Ä: —Å–æ–±—Ä–∞—Ç—å –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–∞–Ω–∏—Ü
all_data = []
for page in range(1, 11):
    print(f"–ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}")
    all_data.extend(parse_page(page))
    time.sleep(1)  # —á—Ç–æ–±—ã –Ω–µ –∑–∞–±–∞–Ω–∏–ª–∏

df = pd.DataFrame(all_data)
df.to_excel("jurhelp_questions.xlsx", index=False)

if __name__ == "__main__":
    test_web_chat() 