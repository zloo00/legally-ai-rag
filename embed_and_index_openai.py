import os
import openai
from dotenv import load_dotenv
from pinecone import Pinecone, ServerlessSpec
from tqdm import tqdm

# === –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª—é—á–µ–π ===
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT") or "us-east-1"
INDEX_NAME = os.getenv("PINECONE_INDEX_NAME") or "legally-index"

# === –®–∞–≥ 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ ===
openai.api_key = OPENAI_API_KEY
pc = Pinecone(api_key=PINECONE_API_KEY)

# === –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ===
if INDEX_NAME not in [index.name for index in pc.list_indexes()]:
    print(f"üìé –ò–Ω–¥–µ–∫—Å '{INDEX_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π...")
    pc.create_index(
        name=INDEX_NAME,
        dimension=1536,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region=PINECONE_ENVIRONMENT)
    )
else:
    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å '{INDEX_NAME}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")

index = pc.Index(INDEX_NAME)

# === –®–∞–≥ 4: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ —á–∞–Ω–∫–æ–≤ ===
chunk_dir = "data/chunks"
texts = []
metadatas = []

for filename in os.listdir(chunk_dir):
    path = os.path.join(chunk_dir, filename)
    with open(path, "r", encoding="utf-8") as f:
        text = f.read().strip()
        if len(text) > 10:
            texts.append(text)
            metadatas.append({"filename": filename})

# === –®–∞–≥ 5: –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ===
def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    res = openai.embeddings.create(input=[text], model=model)
    return res.data[0].embedding


# === –®–∞–≥ 6: –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ Pinecone ===
batch_size = 100
for i in tqdm(range(0, len(texts), batch_size), desc="üì¶ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Pinecone"):
    batch_texts = texts[i:i + batch_size]
    batch_ids = [f"doc-{i + j}" for j in range(len(batch_texts))]
    batch_embeddings = [get_embedding(text) for text in batch_texts]

    index.upsert(vectors=[
        {
            "id": batch_ids[j],
            "values": batch_embeddings[j],
            "metadata": metadatas[i + j]
        } for j in range(len(batch_texts))
    ])

print("‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
